{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于飞桨实现乒乓球时序动作定位大赛 ：B榜第18名方案\n",
    "\n",
    "## 方案说明\n",
    "本项目基于基线，对BMN模型进行了些许修改\n",
    "\n",
    "## 赛题介绍\n",
    "\n",
    "在众多大规模视频分析情景中，从冗长未经修剪的视频中定位并识别短时间内发生的人体动作成为一个备受关注的课题。当前针对人体动作检测的解决方案在大规模视频集上难以奏效，高效地处理大规模视频数据仍然是计算机视觉领域一个充满挑战的任务。其核心问题可以分为两部分，一是动作识别算法的复杂度仍旧较高，二是缺少能够产生更少视频提案数量的方法（更加关注短时动作本身的提案）。\n",
    "\n",
    "这里所指的视频动作提案是指一些包含特定动作的候选视频片段。为了能够适应大规模视频分析任务，时序动作提案应该尽可能满足下面两个需求：\n",
    "（1）更高的处理效率，例如可以设计出使时序视频片段编码和打分更高效的机制；\n",
    "（2）更强的判别性能，例如可以准确定位动作发生的时间区间。\n",
    "\n",
    "本次比赛旨在激发更多的开发者和研究人员关注并参与有关视频动作定位的研究，创建性能更出色的动作定位模型。\n",
    "\n",
    "## 数据集介绍\n",
    "\n",
    "本次比赛的数据集包含了19-21赛季兵乓球国际比赛（世界杯、世锦赛、亚锦赛，奥运会）和国内比赛（全运会，乒超联赛）中标准单机位高清转播画面的特征信息，共包含912条视频特征文件，每个视频时长在0～6分钟不等，特征维度为2048，以pkl格式保存。我们对特征数据中面朝镜头的运动员的回合内挥拍动作进行了标注，单个动作时常在0～2秒不等，训练数据为729条标注视频，A测数据为91条视频，B测数据为92条视频，训练数据标签以json格式给出。\n",
    "\n",
    "## 对模型的修改\n",
    "### 修改前模型\n",
    "```\n",
    "        #Base Module\n",
    "        y1 = self.b_conv1(x)\n",
    "        y1 = self.b_conv1_act(y1)\n",
    "        y1 = self.b_conv2(y1)\n",
    "        y1 = self.b_conv2_act(y1)\n",
    "```\n",
    "x输入后，经过基础层（Base Module）之后，分别输入到三个不同的处理层（TEM，PEM，BM）。\n",
    "\n",
    "### 修改后模型\n",
    "```\n",
    "        #Base Module\n",
    "        y1 = self.b_conv1(x)\n",
    "        y1 = self.b_conv1_act(y1)\n",
    "        y1 = self.b_conv2(y1)\n",
    "        y1 = self.b_conv2_act(y1)\n",
    "\n",
    "        y2 = self.b_conv1_1(x)\n",
    "        y2 = self.b_conv1_act_1(y2)\n",
    "        y2 = self.b_conv2_1(y2)\n",
    "        y2 = self.b_conv2_act_1(y2)\n",
    "```\n",
    "x输入后，经过两个基础层后，TEM和PEM对y1进行处理，得到时间信息，BM层对y2进行处理得到类别信息。\n",
    "\n",
    "这种处理方式目的是促使网络对类别信息和时间信息侧重地去学习不同的特征。\n",
    "\n",
    "### 修改后的BMN代码\n",
    "代码附于文末\n",
    "\n",
    "## checkpoints与如何测试\n",
    "checkpoints为BMN_epoch_00008.pdparams\n",
    "\n",
    "运行PredictB.ipynb即可复现B榜结果\n",
    "\n",
    "## 数据集预处理\n",
    "\n",
    "本方案采用PaddleVideo中的BMN模型。BMN模型是百度自研，2019年ActivityNet夺冠方案，为视频动作定位问题中proposal的生成提供高效的解决方案，在PaddlePaddle上首次开源。此模型引入边界匹配(Boundary-Matching, BM)机制来评估proposal的置信度，按照proposal开始边界的位置及其长度将所有可能存在的proposal组合成一个二维的BM置信度图，图中每个点的数值代表其所对应的proposal的置信度分数。网络由三个模块组成，基础模块作为主干网络处理输入的特征序列，TEM模块预测每一个时序位置属于动作开始、动作结束的概率，PEM模块生成BM置信度图。\n",
    "\n",
    "本赛题中的数据包含912条ppTSM抽取的视频特征，特征保存为pkl格式，文件名对应视频名称，读取pkl之后以(num_of_frames, 2048)向量形式代表单个视频特征。其中num_of_frames是不固定的，同时数量也比较大，所以pkl的文件并不能直接用于训练。同时由于乒乓球每个动作时间非常短，为了可以让模型更好的识别动作，所以这里将数据进行分割。\n",
    "\n",
    "\n",
    "1. 首先解压数据集\n",
    "执行以下命令解压数据集，解压之后将压缩包删除，保证项目空间小于100G。否则项目会被终止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T22:49:51.560955Z",
     "iopub.status.busy": "2022-02-26T22:49:51.560428Z",
     "iopub.status.idle": "2022-02-26T22:59:34.674003Z",
     "shell.execute_reply": "2022-02-26T22:59:34.673108Z",
     "shell.execute_reply.started": "2022-02-26T22:49:51.560901Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/data\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/data/\n",
    "!tar xf data122998/Features_competition_train.tar.gz\n",
    "!tar xf data123004/Features_competition_test_A.tar.gz\n",
    "!cp data122998/label_cls14_train.json .\n",
    "!rm -rf data12*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 解压好数据之后，首先对label标注文件进行分割。执行以下脚本分割标注文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T23:02:48.892331Z",
     "iopub.status.busy": "2022-02-26T23:02:48.891741Z",
     "iopub.status.idle": "2022-02-26T23:02:50.753875Z",
     "shell.execute_reply": "2022-02-26T23:02:50.752980Z",
     "shell.execute_reply.started": "2022-02-26T23:02:48.892291Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12597\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "source_path = \"/home/aistudio/data/label_cls14_train.json\"\n",
    "\n",
    "annos = json.load(open(source_path))\n",
    "fps = annos['fps']\n",
    "annos = annos['gts']\n",
    "new_annos = {}\n",
    "max_frams = 0\n",
    "\n",
    "for anno in annos:\n",
    "    if anno['total_frames'] > max_frams:\n",
    "        max_frams = anno['total_frames']\n",
    "    for i in range(9000//100):\n",
    "        subset = 'training'\n",
    "        clip_start = i * 4\n",
    "        clip_end = (i + 1) * 4\n",
    "        video_name = anno['url'].split('.')[0] + f\"_{i}\"\n",
    "        new_annos[video_name] = {\n",
    "            'duration_second': 100 / fps,\n",
    "            'subset': subset,\n",
    "            'duration_frame': 100,\n",
    "            'annotations': [],\n",
    "            'feature_frame': -1\n",
    "\n",
    "        }\n",
    "        actions = anno['actions']\n",
    "        for act in actions:\n",
    "            start_id = act['start_id']\n",
    "            end_id = act['end_id']\n",
    "            new_start_id = -1\n",
    "            new_end_id = -1\n",
    "            if start_id > clip_start and end_id < clip_end:\n",
    "                new_start_id = start_id - clip_start\n",
    "                new_end_id = end_id - clip_start\n",
    "            elif start_id < clip_start < end_id < clip_end:\n",
    "                new_start_id = 0\n",
    "                new_end_id = end_id - clip_start\n",
    "            elif clip_start < start_id < clip_end < end_id:\n",
    "                new_start_id = start_id - clip_start\n",
    "                new_end_id = 4\n",
    "            elif start_id < clip_start < clip_end < end_id:\n",
    "                new_start_id = 0\n",
    "                new_end_id = 4\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            new_annos[video_name]['annotations'].append({\n",
    "                'segment': [round(new_start_id, 2), round(new_end_id, 2)],\n",
    "                'label': str(act['label_ids'][0])\n",
    "            })\n",
    "        if len(new_annos[video_name]['annotations']) == 0:\n",
    "            new_annos.pop(video_name)\n",
    "\n",
    "\n",
    "json.dump(new_annos, open('new_label_cls14_train.json', 'w+'))\n",
    "print(len(list(new_annos.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行完毕后，在data目录中生成了新的标注文件new_label_cls14_train.json。下面开始分割训练集和测试集的数据。\n",
    "\n",
    "3. 执行以下脚本，分割训练集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-02-26T23:06:18.548121Z",
     "iopub.status.busy": "2022-02-26T23:06:18.547613Z",
     "iopub.status.idle": "2022-02-26T23:11:27.261978Z",
     "shell.execute_reply": "2022-02-26T23:11:27.261184Z",
     "shell.execute_reply.started": "2022-02-26T23:06:18.548079Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0227 07:06:21.816072   150 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0227 07:06:21.820129   150 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import pickle\n",
    "import paddle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "file_list = glob.glob(\"/home/aistudio/data/Features_competition_train/*.pkl\")\n",
    "\n",
    "max_frames = 9000\n",
    "\n",
    "npy_path = (\"/home/aistudio/data/Features_competition_train/npy/\")\n",
    "if not osp.exists(npy_path):\n",
    "    os.makedirs(npy_path)\n",
    "\n",
    "for f in file_list:\n",
    "    video_feat = pickle.load(open(f, 'rb'))\n",
    "    tensor = paddle.to_tensor(video_feat['image_feature'])\n",
    "    pad_num = 9000 - tensor.shape[0]\n",
    "    pad1d = paddle.nn.Pad1D([0, pad_num])\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "    tensor = paddle.unsqueeze(tensor, axis=0)\n",
    "    tensor = pad1d(tensor)\n",
    "    tensor = paddle.squeeze(tensor, axis=0)\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "\n",
    "    sps = paddle.split(tensor, num_or_sections=90, axis=0)\n",
    "    for i, s in enumerate(sps):\n",
    "        file_name = osp.join(npy_path, f.split('/')[-1].split('.')[0] + f\"_{i}.npy\")\n",
    "        np.save(file_name, s.detach().numpy())\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T23:33:56.267229Z",
     "iopub.status.busy": "2022-02-26T23:33:56.266725Z",
     "iopub.status.idle": "2022-02-26T23:33:59.536290Z",
     "shell.execute_reply": "2022-02-26T23:33:59.535431Z",
     "shell.execute_reply.started": "2022-02-26T23:33:56.267189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm /home/aistudio/data/Features_competition_train/*.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行后在data/Features_competition_train/npy目录下生成了训练用的numpy数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T23:34:01.186609Z",
     "iopub.status.busy": "2022-02-26T23:34:01.185637Z",
     "iopub.status.idle": "2022-02-26T23:34:38.172659Z",
     "shell.execute_reply": "2022-02-26T23:34:38.171969Z",
     "shell.execute_reply.started": "2022-02-26T23:34:01.186567Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import paddle\n",
    "\n",
    "file_list = glob.glob(\"/home/aistudio/data/Features_competition_test_A/*.pkl\")\n",
    "\n",
    "max_frames = 9000\n",
    "\n",
    "npy_path = (\"/home/aistudio/data/Features_competition_test_A/npy/\")\n",
    "if not osp.exists(npy_path):\n",
    "    os.makedirs(npy_path)\n",
    "\n",
    "for f in file_list:\n",
    "    video_feat = pickle.load(open(f, 'rb'))\n",
    "    tensor = paddle.to_tensor(video_feat['image_feature'])\n",
    "    pad_num = 9000 - tensor.shape[0]\n",
    "    pad1d = paddle.nn.Pad1D([0, pad_num])\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "    tensor = paddle.unsqueeze(tensor, axis=0)\n",
    "    tensor = pad1d(tensor)\n",
    "    tensor = paddle.squeeze(tensor, axis=0)\n",
    "    tensor = paddle.transpose(tensor, [1, 0])\n",
    "\n",
    "    sps = paddle.split(tensor, num_or_sections=90, axis=0)\n",
    "    for i, s in enumerate(sps):\n",
    "        file_name = osp.join(npy_path, f.split('/')[-1].split('.')[0] + f\"_{i}.npy\")\n",
    "        np.save(file_name, s.detach().numpy())\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "数据集分割好之后，可以开始训练模型，使用以下命令进行模型训练。首先需要安装PaddleVideo的依赖包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleVideo/\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleVideo/\n",
    "!python main.py -c configs/localization/bmn.yaml \\\n",
    "                -w /home/aistudio/BMN_epoch_00004.pdparams\n",
    "                # -w /home/aistudio/PaddleVideo/output/BMN/BMN_epoch_00006.pdparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 模型导出\n",
    "将训练好的模型导出用于推理预测，执行以下脚本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T23:35:49.686687Z",
     "iopub.status.busy": "2022-02-26T23:35:49.685999Z",
     "iopub.status.idle": "2022-02-26T23:36:00.788267Z",
     "shell.execute_reply": "2022-02-26T23:36:00.787474Z",
     "shell.execute_reply.started": "2022-02-26T23:35:49.686637Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/PaddleVideo\n",
      "Building model(BMN)...\n",
      "W0227 07:35:51.439486  4758 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0227 07:35:51.443939  4758 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "Loading params from (output/BMN/BMN_epoch_00004.pdparams)...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "model (BMN) has been already saved in (inference/BMN).\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/PaddleVideo/\n",
    "!python tools/export_model.py -c configs/localization/bmn.yaml -p output/BMN/BMN_epoch_00004.pdparams -o inference/BMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理预测\n",
    "\n",
    "使用导出的模型进行推理预测，执行以下命令。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%cd /home/aistudio/PaddleVideo/\n",
    "!python tools/predict.py --input_file /home/aistudio/data/Features_competition_test_A/npy \\\n",
    " --config configs/localization/bmn.yaml \\\n",
    " --model_file inference/BMN/BMN.pdmodel \\\n",
    " --params_file inference/BMN/BMN.pdiparams \\\n",
    " --use_gpu=True \\\n",
    " --use_tensorrt=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面程序输出的json文件是分割后的预测结果，还需要将这些文件组合到一起。执行以下脚本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T13:00:24.817350Z",
     "iopub.status.busy": "2022-02-26T13:00:24.816817Z",
     "iopub.status.idle": "2022-02-26T13:00:37.203870Z",
     "shell.execute_reply": "2022-02-26T13:00:37.202905Z",
     "shell.execute_reply.started": "2022-02-26T13:00:24.817311Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "json_path = \"/home/aistudio/data/Features_competition_test_A/npy\"\n",
    "json_files = glob.glob(os.path.join(json_path, '*_*.json'))\n",
    "\n",
    "submit_dic = {\"version\": None,\n",
    "              \"results\": {},\n",
    "              \"external_data\": {}\n",
    "              }\n",
    "results = submit_dic['results']\n",
    "for json_file in json_files:\n",
    "    j = json.load(open(json_file, 'r'))\n",
    "    old_video_name = list(j.keys())[0]\n",
    "    video_name = list(j.keys())[0].split('/')[-1].split('.')[0]\n",
    "    video_name, video_no = video_name.split('_')\n",
    "    start_id = int(video_no) * 4\n",
    "    if len(j[old_video_name]) == 0:\n",
    "        continue\n",
    "    for i, top in enumerate(j[old_video_name]):\n",
    "        if video_name in results.keys():\n",
    "            results[video_name].append({'score': round(top['score'], 2),\n",
    "                                        'segment': [round(top['segment'][0] + start_id, 2), round(top['segment'][1] + start_id, 2)]})\n",
    "        else:\n",
    "            results[video_name] = [{'score':round(top['score'], 2),\n",
    "                                        'segment': [round(top['segment'][0] + start_id, 2), round(top['segment'][1] + start_id, 2)]}]\n",
    "\n",
    "json.dump(submit_dic, open('/home/aistudio/submission.json', 'w', encoding='utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后会在用户目录生成submission.json文件，压缩后下载提交即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-26T13:00:55.398231Z",
     "iopub.status.busy": "2022-02-26T13:00:55.397161Z",
     "iopub.status.idle": "2022-02-26T13:00:56.682025Z",
     "shell.execute_reply": "2022-02-26T13:00:56.681102Z",
     "shell.execute_reply.started": "2022-02-26T13:00:55.398193Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio\n",
      "updating: submission.json (deflated 91%)\n"
     ]
    }
   ],
   "source": [
    "%cd /home/aistudio/\n",
    "!zip submission.zip submission.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 原基线作者的话\n",
    "\n",
    "1. 可以增加训练的epoch数量。\n",
    "2. 可以调整学习率策略，比如warmup和余弦退火等。\n",
    "3. 我认为最关键的还是数据预处理，本方案只是简单的每4秒划分，其实并不合理，会出现将一个动作划到两个文件可能。可参照[FootballAciton](https://github.com/PaddlePaddle/PaddleVideo/blob/application/FootballAction/datasets/script/get_instance_for_bmn.py)的划分方法，进一步优化训练数据。\n",
    "\n",
    "最后祝大家都能获得好成绩。\n",
    "\n",
    "欢迎大家关注我的公众号：人工智能研习社\n",
    "获取最新的比赛Baseline,可在后台回复比赛名称或比赛网址，我会尽量为大家提供Baseline。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 修改后的BMN文件\n",
    "代替PaddleVideo/paddlevideo/modeling/backbones/bmn.py即可\n",
    "```\n",
    "# Copyright (c) 2020  PaddlePaddle Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\"\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle import ParamAttr\n",
    "from ..registry import BACKBONES\n",
    "\n",
    "\n",
    "def _get_interp1d_bin_mask(seg_xmin, seg_xmax, tscale, num_sample,\n",
    "                           num_sample_perbin):\n",
    "    \"\"\" generate sample mask for a boundary-matching pair \"\"\"\n",
    "    plen = float(seg_xmax - seg_xmin)\n",
    "    plen_sample = plen / (num_sample * num_sample_perbin - 1.0)\n",
    "    total_samples = [\n",
    "        seg_xmin + plen_sample * ii\n",
    "        for ii in range(num_sample * num_sample_perbin)\n",
    "    ]\n",
    "    p_mask = []\n",
    "    for idx in range(num_sample):\n",
    "        bin_samples = total_samples[idx * num_sample_perbin:(idx + 1) *\n",
    "                                    num_sample_perbin]\n",
    "        bin_vector = np.zeros([tscale])\n",
    "        for sample in bin_samples:\n",
    "            sample_upper = math.ceil(sample)\n",
    "            sample_decimal, sample_down = math.modf(sample)\n",
    "            if (tscale - 1) >= int(sample_down) >= 0:\n",
    "                bin_vector[int(sample_down)] += 1 - sample_decimal\n",
    "            if (tscale - 1) >= int(sample_upper) >= 0:\n",
    "                bin_vector[int(sample_upper)] += sample_decimal\n",
    "        bin_vector = 1.0 / num_sample_perbin * bin_vector\n",
    "        p_mask.append(bin_vector)\n",
    "    p_mask = np.stack(p_mask, axis=1)\n",
    "    return p_mask\n",
    "\n",
    "\n",
    "def get_interp1d_mask(tscale, dscale, prop_boundary_ratio, num_sample,\n",
    "                      num_sample_perbin):\n",
    "    \"\"\" generate sample mask for each point in Boundary-Matching Map \"\"\"\n",
    "    mask_mat = []\n",
    "    for start_index in range(tscale):\n",
    "        mask_mat_vector = []\n",
    "        for duration_index in range(dscale):\n",
    "            if start_index + duration_index < tscale:\n",
    "                p_xmin = start_index\n",
    "                p_xmax = start_index + duration_index\n",
    "                center_len = float(p_xmax - p_xmin) + 1\n",
    "                sample_xmin = p_xmin - center_len * prop_boundary_ratio\n",
    "                sample_xmax = p_xmax + center_len * prop_boundary_ratio\n",
    "                p_mask = _get_interp1d_bin_mask(sample_xmin, sample_xmax,\n",
    "                                                tscale, num_sample,\n",
    "                                                num_sample_perbin)\n",
    "            else:\n",
    "                p_mask = np.zeros([tscale, num_sample])\n",
    "            mask_mat_vector.append(p_mask)\n",
    "        mask_mat_vector = np.stack(mask_mat_vector, axis=2)\n",
    "        mask_mat.append(mask_mat_vector)\n",
    "    mask_mat = np.stack(mask_mat, axis=3)\n",
    "    mask_mat = mask_mat.astype(np.float32)\n",
    "\n",
    "    sample_mask = np.reshape(mask_mat, [tscale, -1])\n",
    "    return sample_mask\n",
    "\n",
    "\n",
    "def init_params(name, in_channels, kernel_size):\n",
    "    fan_in = in_channels * kernel_size * 1\n",
    "    k = 1. / math.sqrt(fan_in)\n",
    "    param_attr = ParamAttr(name=name,\n",
    "                           initializer=paddle.nn.initializer.Uniform(low=-k,\n",
    "                                                                     high=k))\n",
    "    return param_attr\n",
    "\n",
    "\n",
    "@BACKBONES.register()\n",
    "class BMN(paddle.nn.Layer):\n",
    "    \"\"\"BMN model from\n",
    "    `\"BMN: Boundary-Matching Network for Temporal Action Proposal Generation\" <https://arxiv.org/abs/1907.09702>`_\n",
    "    Args:\n",
    "        tscale (int): sequence length, default 100.\n",
    "        dscale (int): max duration length, default 100.\n",
    "        prop_boundary_ratio (float): ratio of expanded temporal region in proposal boundary, default 0.5.\n",
    "        num_sample (int): number of samples betweent starting boundary and ending boundary of each propoasl, default 32.\n",
    "        num_sample_perbin (int):  number of selected points in each sample, default 3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tscale,\n",
    "        dscale,\n",
    "        prop_boundary_ratio,\n",
    "        num_sample,\n",
    "        num_sample_perbin,\n",
    "        feat_dim=400,\n",
    "    ):\n",
    "        super(BMN, self).__init__()\n",
    "\n",
    "        #init config\n",
    "        self.feat_dim = feat_dim\n",
    "        self.tscale = tscale\n",
    "        self.dscale = dscale\n",
    "        self.prop_boundary_ratio = prop_boundary_ratio\n",
    "        self.num_sample = num_sample\n",
    "        self.num_sample_perbin = num_sample_perbin\n",
    "\n",
    "        self.hidden_dim_1d = 256\n",
    "        self.hidden_dim_2d = 128\n",
    "        self.hidden_dim_3d = 512\n",
    "\n",
    "        # Base Module\n",
    "        self.b_conv1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.feat_dim,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('Base_1_w', self.feat_dim, 3),\n",
    "            bias_attr=init_params('Base_1_b', self.feat_dim, 3))\n",
    "        self.b_conv1_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.b_conv2 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('Base_2_w', self.hidden_dim_1d, 3),\n",
    "            bias_attr=init_params('Base_2_b', self.hidden_dim_1d, 3))\n",
    "        self.b_conv2_act = paddle.nn.ReLU()\n",
    "\n",
    "        # Base Module 2\n",
    "        self.b_conv1_1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.feat_dim,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('Base_1_w_1', self.feat_dim, 3),\n",
    "            bias_attr=init_params('Base_1_b_1', self.feat_dim, 3))\n",
    "        self.b_conv1_act_1 = paddle.nn.ReLU()\n",
    "\n",
    "        self.b_conv2_1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('Base_2_w_1', self.hidden_dim_1d, 3),\n",
    "            bias_attr=init_params('Base_2_b_1', self.hidden_dim_1d, 3))\n",
    "        self.b_conv2_act_1 = paddle.nn.ReLU()\n",
    "\n",
    "        # Temporal Evaluation Module\n",
    "        self.ts_conv1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('TEM_s1_w', self.hidden_dim_1d, 3),\n",
    "            bias_attr=init_params('TEM_s1_b', self.hidden_dim_1d, 3))\n",
    "        self.ts_conv1_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.ts_conv2 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            weight_attr=init_params('TEM_s2_w', self.hidden_dim_1d, 1),\n",
    "            bias_attr=init_params('TEM_s2_b', self.hidden_dim_1d, 1))\n",
    "        self.ts_conv2_act = paddle.nn.Sigmoid()\n",
    "\n",
    "        self.te_conv1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=self.hidden_dim_1d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=4,\n",
    "            weight_attr=init_params('TEM_e1_w', self.hidden_dim_1d, 3),\n",
    "            bias_attr=init_params('TEM_e1_b', self.hidden_dim_1d, 3))\n",
    "        self.te_conv1_act = paddle.nn.ReLU()\n",
    "        self.te_conv2 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "            padding=0,\n",
    "            groups=1,\n",
    "            weight_attr=init_params('TEM_e2_w', self.hidden_dim_1d, 1),\n",
    "            bias_attr=init_params('TEM_e2_b', self.hidden_dim_1d, 1))\n",
    "        self.te_conv2_act = paddle.nn.Sigmoid()\n",
    "\n",
    "        #Proposal Evaluation Module\n",
    "        self.p_conv1 = paddle.nn.Conv1D(\n",
    "            in_channels=self.hidden_dim_1d,\n",
    "            out_channels=self.hidden_dim_2d,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            groups=1,\n",
    "            weight_attr=init_params('PEM_1d_w', self.hidden_dim_1d, 3),\n",
    "            bias_attr=init_params('PEM_1d_b', self.hidden_dim_1d, 3))\n",
    "        self.p_conv1_act = paddle.nn.ReLU()\n",
    "\n",
    "        # init to speed up\n",
    "        sample_mask = get_interp1d_mask(self.tscale, self.dscale,\n",
    "                                        self.prop_boundary_ratio,\n",
    "                                        self.num_sample, self.num_sample_perbin)\n",
    "        self.sample_mask = paddle.to_tensor(sample_mask)\n",
    "        self.sample_mask.stop_gradient = True\n",
    "\n",
    "        self.p_conv3d1 = paddle.nn.Conv3D(\n",
    "            in_channels=128,\n",
    "            out_channels=self.hidden_dim_3d,\n",
    "            kernel_size=(self.num_sample, 1, 1),\n",
    "            stride=(self.num_sample, 1, 1),\n",
    "            padding=0,\n",
    "            weight_attr=ParamAttr(name=\"PEM_3d1_w\"),\n",
    "            bias_attr=ParamAttr(name=\"PEM_3d1_b\"))\n",
    "        self.p_conv3d1_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.p_conv2d1 = paddle.nn.Conv2D(\n",
    "            in_channels=512,\n",
    "            out_channels=self.hidden_dim_2d,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            weight_attr=ParamAttr(name=\"PEM_2d1_w\"),\n",
    "            bias_attr=ParamAttr(name=\"PEM_2d1_b\"))\n",
    "        self.p_conv2d1_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.p_conv2d2 = paddle.nn.Conv2D(\n",
    "            in_channels=128,\n",
    "            out_channels=self.hidden_dim_2d,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_attr=ParamAttr(name=\"PEM_2d2_w\"),\n",
    "            bias_attr=ParamAttr(name=\"PEM_2d2_b\"))\n",
    "        self.p_conv2d2_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.p_conv2d3 = paddle.nn.Conv2D(\n",
    "            in_channels=128,\n",
    "            out_channels=self.hidden_dim_2d,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            weight_attr=ParamAttr(name=\"PEM_2d3_w\"),\n",
    "            bias_attr=ParamAttr(name=\"PEM_2d3_b\"))\n",
    "        self.p_conv2d3_act = paddle.nn.ReLU()\n",
    "\n",
    "        self.p_conv2d4 = paddle.nn.Conv2D(\n",
    "            in_channels=128,\n",
    "            out_channels=2,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            weight_attr=ParamAttr(name=\"PEM_2d4_w\"),\n",
    "            bias_attr=ParamAttr(name=\"PEM_2d4_b\"))\n",
    "        self.p_conv2d4_act = paddle.nn.Sigmoid()\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Base Module\n",
    "        y1 = self.b_conv1(x)\n",
    "        y1 = self.b_conv1_act(y1)\n",
    "        y1 = self.b_conv2(y1)\n",
    "        y1 = self.b_conv2_act(y1)\n",
    "\n",
    "        y2 = self.b_conv1_1(x)\n",
    "        y2 = self.b_conv1_act_1(y2)\n",
    "        y2 = self.b_conv2_1(y2)\n",
    "        y2 = self.b_conv2_act_1(y2)\n",
    "\n",
    "        #TEM\n",
    "        xs = self.ts_conv1(y1)\n",
    "        xs = self.ts_conv1_act(xs)\n",
    "        xs = self.ts_conv2(xs)\n",
    "        xs = self.ts_conv2_act(xs)\n",
    "        xs = paddle.squeeze(xs, axis=[1])\n",
    "        xe = self.te_conv1(y1)\n",
    "        xe = self.te_conv1_act(xe)\n",
    "        xe = self.te_conv2(xe)\n",
    "        xe = self.te_conv2_act(xe)\n",
    "        xe = paddle.squeeze(xe, axis=[1])\n",
    "\n",
    "        #PEM\n",
    "        xp = self.p_conv1(y2)\n",
    "        xp = self.p_conv1_act(xp)\n",
    "        #BM layer\n",
    "        xp = paddle.matmul(xp, self.sample_mask)\n",
    "        xp = paddle.reshape(xp, shape=[0, 0, -1, self.dscale, self.tscale])\n",
    "\n",
    "        xp = self.p_conv3d1(xp)\n",
    "        xp = self.p_conv3d1_act(xp)\n",
    "        xp = paddle.squeeze(xp, axis=[2])\n",
    "        xp = self.p_conv2d1(xp)\n",
    "        xp = self.p_conv2d1_act(xp)\n",
    "        xp = self.p_conv2d2(xp)\n",
    "        xp = self.p_conv2d2_act(xp)\n",
    "        xp = self.p_conv2d3(xp)\n",
    "        xp = self.p_conv2d3_act(xp)\n",
    "        xp = self.p_conv2d4(xp)\n",
    "        xp = self.p_conv2d4_act(xp)\n",
    "        return xp, xs, xe\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
